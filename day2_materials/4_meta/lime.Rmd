---
title: "Explaining image classification with LIME"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---


```{r}
library(keras)
library(lime)
library(magick)
```


## Data prep

We're going to dive deep into the secrets of fashion now. Here's the training data.

```{r}
fashion <- dataset_fashion_mnist()

x_train <- fashion$train$x / 255
dim(x_train) <- c(dim(x_train), 1)

y_train <- fashion$train$y
# take care: these range from 0 to 9 (just like MNIST)
range(y_train)

class_names = c('T-shirt/top',
                'Trouser',
                'Pullover',
                'Dress',
                'Coat', 
                'Sandal',
                'Shirt',
                'Sneaker',
                'Bag',
                'Ankle boot')
```


## Model

Let's already start training the model while we're talking. It's just a simple CNN.

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = "same",
    input_shape = c(28, 28, 1),
    activation = "relu"
  ) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = "same",
    activation = "relu"
  ) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

model %>% compile(
  optimizer = "adam",
  loss = "sparse_categorical_crossentropy",
  metrics = "accuracy"
)

model %>% fit(
  x = x_train,
  y = y_train,
  batch_size = 100,
  epochs = 20
)
```


## Explanation

Here are some clothes from the test set, so you could pick a piece you'd like to explain.

```{r}
x_test <- fashion$test$x 
y_test <- fashion$test$y

par(mfcol=c(6,6))
par(mar=c(0, 0, 1.5, 0), xaxs='i', yaxs='i')
for (i in 1:36) { 
  img <- x_test[i, , ]
  img <- t(apply(img, 2, rev)) 
  image(1:28, 1:28, img, col = gray((0:255)/255), xaxt = 'n', yaxt = 'n',
        main = paste(class_names[y_test[i] + 1]))
}
```


### Create an explainer

First, you will need to create an `explainer` (a closure) using the `lime` factory function.
In the case of images, you will have to pass in

- a path to an image file,
- a reference to the model to be used for prediction
- a function to be used for preprocessing 

 

#### Save an image to disk

`lime` needs a file path as first argument, so we are going to save an image to disk.
Pick anything to your liking.


```{r}
img_path <- "/tmp/image4lime.png"

example_image <- x_test[9, , ] / 255 # pick whatever you like here
dim(example_image) <- c(28, 28, 1)
img <- example_image %>% image_read()
img %>% image_write(img_path)
```



#### Create a pre-processing function for LIME to use

The pre-processing function should be able to work with a list of paths.
Here's a skeleton that to fill in as you see fit.

```{r}
image_prep <- function(x) {
  arrays <- lapply(x, function(path) {
    # fill in here
  })
  do.call(abind::abind, c(arrays, list(along = 1)))
}
```


##### Explainer

Now create the explainer. You should wrap the model into `as classifier`, passing the target labels to that function.
Note that this wrapper is not optional - LIME needs it to be informed about the model type.

```{r}
# fill in here
```


##### Get a prediction

Before we look at explanations, let's get a prediction.
This is also a good way to test the preprocessing function.

```{r}
# fill in here
```


Which is the most probable class?

```{r}
# fill in here
```


#### Superpixels

LIME determines essential image areas by successively masking homogeneous regions - the so-called superpixels.
Explanation results will depend on adequacy of superpixel segmentation used.

Play around a bit with `plot_superpixels` to get a feeling for this.


```{r}
# fill in here
```


##### Explanation

Now use `explain` to find out what LIME has to say about the why of the model's "decision".
Make sure to play around with different parameter settings, e.g. as regards superpixel segmentation.

```{r}
# fill in here
```

Plot the explanation. Note too that you can view regions that contradict the model's findings.

```{r}
# fill in here
```


